<!DOCTYPE html><html lang="en"><head>
        <title>
            AI-102-AIEngineer
        </title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" crossorigin="anonymous">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" crossorigin="anonymous">
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/vs.min.css">
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <link rel="stylesheet" href="../assets/css/style_v%3D.css">
    </head>
    <body data-spy="scroll" data-target="#linksMenu">
    <nav class="navbar navbar-expand-lg navbar-dark bg-black">
        <div class="container d-flex justify-content-between">
            <a class="my-1 title text-azure text-uppercase" href="../">
                AI-102-AIEngineer
            </a>
            <a href="https://github.com/MicrosoftLearning/AI-102-AIEngineer" target="_blank" class="btn btn-sm btn-outline-secondary text-light">
                <i class="fa fa-github" aria-hidden="true"></i>
                <span class="ml-2">GitHub</span>
            </a>
        </div>
    </nav>
    <div class="container">
        <main class="row extra-padding">
            <aside class="col-sm-2">       
                <nav id="linksMenu" class="toc sticky-top">
                    <ul class="nav navbar-nav flex-column">
                    </ul>
                </nav>         
            </aside>
            <hr class>
            <article class="col-sm-10 mb-5">
                <h1 id="classify-images-with-custom-vision">Classify Images with Custom Vision</h1>

<p>The <strong>Custom Vision</strong> service enables you to create computer vision models that are trained on your own images. You can use it to train <em>image classification</em> and <em>object detection</em> models; which you can then publish and consume from applications.</p>

<p>In this exercise, you will use the Custom Vision service to train an image classification model that can identify three classes of fruit (apple, banana, and orange).</p>

<h2 id="clone-the-repository-for-this-course">Clone the repository for this course</h2>

<p>If you have not already cloned <strong>AI-102-AIEngineer</strong> code repository to the environment where you‚Äôre working on this lab, follow these steps to do so. Otherwise, open the cloned folder in Visual Studio Code.</p>

<ol>
  <li>Start Visual Studio Code.</li>
  <li>Open the palette (SHIFT+CTRL+P) and run a <strong>Git: Clone</strong> command to clone the <code>https://github.com/MicrosoftLearning/AI-102-AIEngineer</code> repository to a local folder (it doesn‚Äôt matter which folder).</li>
  <li>When the repository has been cloned, open the folder in Visual Studio Code.</li>
  <li>
    <p>Wait while additional files are installed to support the C# code projects in the repo.</p>

    <blockquote>
      <p><strong>Note</strong>: If you are prompted to add required assets to build and debug, select <strong>Not Now</strong>.</p>
    </blockquote>
  </li>
</ol>

<h2 id="create-custom-vision-resources">Create Custom Vision resources</h2>

<p>Before you can train a model, you will need Azure resources for <em>training</em> and <em>prediction</em>. You can create <strong>Custom Vision</strong> resources for each of these tasks, or you can create a single <strong>Cognitive Services</strong> resource and use it for either (or both).</p>

<p>In this exercise, you‚Äôll create <strong>Custom Vision</strong> resources for training and prediction so that you can manage access and costs for these workloads separately.</p>

<ol>
  <li>In a new browser tab, open the Azure portal at <code>https://portal.azure.com</code>, and sign in using the Microsoft account associated with your Azure subscription.</li>
  <li>Select the <strong>ÔºãCreate a resource</strong> button, search for <em>custom vision</em>, and create a <strong>Custom Vision</strong> resource with the following settings:
    <ul>
      <li><strong>Create options</strong>: Both</li>
      <li><strong>Subscription</strong>: <em>Your Azure subscription</em></li>
      <li><strong>Resource group</strong>: <em>Choose or create a resource group (if you are using a restricted subscription, you may not have permission to create a new resource group - use the one provided)</em></li>
      <li><strong>Name</strong>: <em>Enter a unique name</em></li>
      <li><strong>Training location</strong>: <em>Choose any available region</em></li>
      <li><strong>Training pricing tier</strong>: F0</li>
      <li><strong>Prediction location</strong>: <em>The same region as the training resource</em></li>
      <li><strong>Prediction pricing tier</strong>: F0</li>
    </ul>

    <blockquote>
      <p><strong>Note</strong>: If you already have an F0 custom vision service in your subscription, select <strong>S0</strong> for this one.</p>
    </blockquote>
  </li>
  <li>Wait for the resources to be created, and then view the deployment details and note that two Custom Vision resources are provisioned; one for training, and another for prediction. You can view these by navigating to the resource group where you created them.</li>
</ol>

<blockquote>
  <p><strong>Important</strong>: Each resource has its own <em>endpoint</em> and <em>keys</em>, which are used to manage access from your code. To train an image classification model, your code must use the <em>training</em> resource (with its endpoint and key); and to use the trained model to predict image classes, your code must use the <em>prediction</em> resource (with its endpoint and key).</p>
</blockquote>

<h2 id="create-a-custom-vision-project">Create a Custom Vision project</h2>

<p>To train an image classification model, you need to create a Custom Vision project based on your training resource. To do this, you‚Äôll use the Custom Vision portal.</p>

<ol>
  <li>In Visual Studio Code, view the training images in the <strong>17-image-classification/training-images</strong> folder where you cloned the repository. This folder contains subfolders of apple, banana, and orange images.</li>
  <li>In a new browser tab, open the Custom Vision portal at <code>https://customvision.ai</code>. If prompted, sign in using the Microsoft account associated with your Azure subscription and agree to the terms of service.</li>
  <li>In the Custom Vision portal, create a new project with the following settings:
    <ul>
      <li><strong>Name</strong>: Classify Fruit</li>
      <li><strong>Description</strong>: Image classification for fruit</li>
      <li><strong>Resource</strong>: <em>The Custom Vision resource you created previously</em></li>
      <li><strong>Project Types</strong>: Classification</li>
      <li><strong>Classification Types</strong>: Multiclass (single tag per image)</li>
      <li><strong>Domains</strong>: Food</li>
    </ul>
  </li>
  <li>In the new project, click <strong>[+] Add images</strong>, and select all of the files in the <strong>training-images/apple</strong> folder you viewed previously. Then upload the image files, specifying the tag <em>apple</em>, like this:</li>
</ol>

<p><a href="images/upload_apples.jpg" target="_blank"><img src="images/upload_apples.jpg" alt="Upload apple with apple tag"></a></p>

<ol>
  <li>Repeat the previous step to upload the images in the <strong>banana</strong> folder with the tag <em>banana</em>, and the images in the <strong>orange</strong> folder with the tag <em>orange</em>.</li>
  <li>Explore the images you have uploaded in the Custom Vision project - there should be 15 images of each class, like this:</li>
</ol>

<p><a href="images/fruit.jpg" target="_blank"><img src="images/fruit.jpg" alt="Tagged images of fruit - 15 apples, 15 bananas, and 15 oranges"></a></p>

<ol>
  <li>In the Custom Vision project, above the images, click <strong>Train</strong> to train a classification model using the tagged images. Select the <strong>Quick Training</strong> option, and then wait for the training iteration to complete (this may take a minute or so).</li>
  <li>When the model iteration has been trained, review the <em>Precision</em>, <em>Recall</em>, and <em>AP</em> performance metrics - these measure the prediction accuracy of the classification model, and should all be high.</li>
</ol>

<blockquote>
  <p><strong>Note</strong>: The performance metrics are based on a probability threshold of 50% for each prediction (in other words, if the model calculates a 50% or higher probability that an image is of a particular class, then that class is predicted). You can adjust this at the top-left of the page.</p>
</blockquote>

<h2 id="test-the-model">Test the model</h2>

<p>Now that you‚Äôve trained the model, you can test it.</p>

<ol>
  <li>Above the performance metrics, click <strong>Quick Test</strong>.</li>
  <li>In the <strong>Image URL</strong> box, type <code>https://aka.ms/apple-image</code> and click ‚ûî</li>
  <li>View the predictions returned by your model - the probability score for <em>apple</em> should be the highest, like this:</li>
</ol>

<p><a href="images/test-apple.jpg" target="_blank"><img src="images/test-apple.jpg" alt="An image with a class prediction of apple"></a></p>

<ol>
  <li>Close the <strong>Quick Test</strong> window.</li>
</ol>

<h2 id="view-the-project-settings">View the project settings</h2>

<p>The project you have created has been assigned a unique identifier, which you will need to specify in any code that interacts with it.</p>

<ol>
  <li>Click the <em>settings</em> (‚öô) icon at the top right of the <strong>Performance</strong> page to view the project settings.</li>
  <li>Under <strong>General</strong> (on the left), note the <strong>Project Id</strong> that uniquely identifies this project.</li>
  <li>On the right, under <strong>Resources</strong> note that the details for the <em>training</em> resource, including its key and endpoint are shown (you can also obtain this information by viewing the resource in the Azure portal).</li>
</ol>

<h2 id="use-the-training-api">Use the <em>training</em> API</h2>

<p>The Custom Vision portal provides a convenient user interface that you can use to upload and tag images, and train models. However, in some scenarios you may want to automate model training by using the Custom Vision training API.</p>

<blockquote>
  <p><strong>Note</strong>: In this exercise, you can choose to use the API from either the <strong>C#</strong> or <strong>Python</strong> SDK. In the steps below, perform the actions appropriate for your preferred language.</p>
</blockquote>

<ol>
  <li>In Visual Studio Code, in the <strong>Explorer</strong> pane, browse to the <strong>17-image_classification</strong> folder and expand the <strong>C-Sharp</strong> or <strong>Python</strong> folder depending on your language preference.</li>
  <li>Right-click the <strong>train-classifier</strong> folder and open an integrated terminal. Then install the Custom Vision Training package by running the appropriate command for your language preference:</li>
</ol>

<p><strong>C#</strong></p>

<div class="code-header mt-3 mb-0 bg-light d-flex justify-content-between border"><span class="mx-2 text-muted text-capitalize font-weight-light">code</span><button class="m-0 btn btn-code btn-sm btn-light codeBtn rounded-0 border-left text-muted font-weight-light" data-clipboard-target="#codeBlock0" type="button"><i class="fa fa-files-o mr-2" aria-hidden="true"></i>Copy</button></div><pre id="codeBlock0" class="mt-0"><code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">dotnet</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">add</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">package</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Microsoft</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.Azure</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.CognitiveServices</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.Vision</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.CustomVision</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.Training</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">--version</span></span> 2<span class="hljs-selector-class"><span class="hljs-selector-class">.0</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.0</span></span>
</code></pre>

<p><strong>Python</strong></p>

<div class="code-header mt-3 mb-0 bg-light d-flex justify-content-between border"><span class="mx-2 text-muted text-capitalize font-weight-light">code</span><button class="m-0 btn btn-code btn-sm btn-light codeBtn rounded-0 border-left text-muted font-weight-light" data-clipboard-target="#codeBlock1" type="button"><i class="fa fa-files-o mr-2" aria-hidden="true"></i>Copy</button></div><pre id="codeBlock1" class="mt-0"><code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">pip</span></span> install azure-cognitiveservices-vision-customvision==<span class="hljs-number"><span class="hljs-number">3</span></span>.<span class="hljs-number"><span class="hljs-number">1</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span>
</code></pre>

<ol>
  <li>View the contents of the <strong>train-classifier</strong> folder, and note that it contains a file for configuration settings:
    <ul>
      <li><strong>C#</strong>: appsettings.json</li>
      <li><strong>Python</strong>: .env</li>
    </ul>

    <p>Open the configuration file and update the configuration values it contains to reflect the endpoint and key for your Custom Vision <em>training</em> resource, and the project ID for the classification project you created previously. Save your changes.</p>
  </li>
  <li>
    <p>Note that the <strong>train-classifier</strong> folder contains a code file for the client application:</p>

    <ul>
      <li><strong>C#</strong>: Program.cs</li>
      <li><strong>Python</strong>: train-classifier.py</li>
    </ul>

    <p>Open the code file and review the code it contains, noting the following details:</p>
    <ul>
      <li>Namespaces from the package you installed are imported</li>
      <li>The <strong>Main</strong> function retrieves the configuration settings, and uses the key and endpoint to create an authenticated <strong>CustomVisionTrainingClient</strong>, which is then used with the project ID to create a <strong>Project</strong> reference to your project.</li>
      <li>The <strong>Upload_Images</strong> function retrieves the tags that are defined in the Custom Vision project and then uploads image files from correspondingly named folders to the project, assigning the appropriate tag ID.</li>
      <li>The <strong>Train_Model</strong> function creates a new training iteration for the project and waits for training to complete.</li>
    </ul>
  </li>
  <li>Return the integrated terminal for the <strong>train-classifier</strong> folder, and enter the following command to run the program:</li>
</ol>

<p><strong>C#</strong></p>

<div class="code-header mt-3 mb-0 bg-light d-flex justify-content-between border"><span class="mx-2 text-muted text-capitalize font-weight-light">code</span><button class="m-0 btn btn-code btn-sm btn-light codeBtn rounded-0 border-left text-muted font-weight-light" data-clipboard-target="#codeBlock2" type="button"><i class="fa fa-files-o mr-2" aria-hidden="true"></i>Copy</button></div><pre id="codeBlock2" class="mt-0"><code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">dotnet</span></span> run
</code></pre>

<p><strong>Python</strong></p>

<div class="code-header mt-3 mb-0 bg-light d-flex justify-content-between border"><span class="mx-2 text-muted text-capitalize font-weight-light">code</span><button class="m-0 btn btn-code btn-sm btn-light codeBtn rounded-0 border-left text-muted font-weight-light" data-clipboard-target="#codeBlock3" type="button"><i class="fa fa-files-o mr-2" aria-hidden="true"></i>Copy</button></div><pre id="codeBlock3" class="mt-0"><code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">python</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">train-classifier</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.py</span></span>
</code></pre>

<ol>
  <li>Wait for the program to end. Then return to your browser and view the <strong>Training Images</strong> page for your project in the Custom Vision portal (refreshing the browser if necessary).</li>
  <li>Verify that some new tagged images have been added to the project. Then view the <strong>Performance</strong> page and verify that a new iteration has been created.</li>
</ol>

<h2 id="publish-the-image-classification-model">Publish the image classification model</h2>

<p>Now you‚Äôre ready to publish your trained model so that it can be used from a client application.</p>

<ol>
  <li>In the Custom Vision portal, on the <strong>Performance</strong> page,  click <strong>üó∏ Publish</strong> to publish the trained model with the following settings:
    <ul>
      <li><strong>Model name</strong>: fruit-classifier</li>
      <li><strong>Prediction Resource</strong>: <em>The <strong>prediction</strong> resource you created previously (<u>not</u> the training resource)</em>.</li>
    </ul>
  </li>
  <li>At the top left of the <strong>Project Settings</strong> page, click the <em>Projects Gallery</em> (üëÅ) icon to return to the Custom Vision portal home page, where your project is now listed.</li>
  <li>On the Custom Vision portal home page, at the top right, click the <em>settings</em> (‚öô) icon to view the settings for your Custom Vision service. Then, under <strong>Resources</strong>, find your <em>prediction</em> resource (<u>not</u> the training resource) to determine its <strong>Key</strong> and <strong>Endpoint</strong> values (you can also obtain this information by viewing the resource in the Azure portal).</li>
</ol>

<h2 id="use-the-image-classifier-from-a-client-application">Use the image classifier from a client application</h2>

<p>Now that you‚Äôve published the image classification model, you can use it from a client application. Once again, you can choose to use <strong>C#</strong> or <strong>Python</strong>.</p>

<ol>
  <li>In Visual Studio Code, in the <strong>17-image-classification</strong> folder, in the subfolder for your preferred language (<strong>C-Sharp</strong> or <strong>Python</strong>), right- the <strong>test-classifier</strong> folder and open an integrated terminal. Then enter the following SDK-specific command to install the Custom Vision Prediction package:</li>
</ol>

<p><strong>C#</strong></p>

<div class="code-header mt-3 mb-0 bg-light d-flex justify-content-between border"><span class="mx-2 text-muted text-capitalize font-weight-light">code</span><button class="m-0 btn btn-code btn-sm btn-light codeBtn rounded-0 border-left text-muted font-weight-light" data-clipboard-target="#codeBlock4" type="button"><i class="fa fa-files-o mr-2" aria-hidden="true"></i>Copy</button></div><pre id="codeBlock4" class="mt-0"><code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">dotnet</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">add</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">package</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Microsoft</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.Azure</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.CognitiveServices</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.Vision</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.CustomVision</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.Prediction</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">--version</span></span> 2<span class="hljs-selector-class"><span class="hljs-selector-class">.0</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.0</span></span>
</code></pre>

<p><strong>Python</strong></p>

<div class="code-header mt-3 mb-0 bg-light d-flex justify-content-between border"><span class="mx-2 text-muted text-capitalize font-weight-light">code</span><button class="m-0 btn btn-code btn-sm btn-light codeBtn rounded-0 border-left text-muted font-weight-light" data-clipboard-target="#codeBlock5" type="button"><i class="fa fa-files-o mr-2" aria-hidden="true"></i>Copy</button></div><pre id="codeBlock5" class="mt-0"><code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">pip</span></span> install azure-cognitiveservices-vision-customvision==<span class="hljs-number"><span class="hljs-number">3</span></span>.<span class="hljs-number"><span class="hljs-number">1</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span>
</code></pre>

<blockquote>
  <p><strong>Note</strong>: The Python SDK package includes both training and prediction packages, and may already be installed.</p>
</blockquote>

<ol>
  <li>Expand the <strong>test-classifier</strong> folder to view the files it contains, which are used to implement a test client application for your image classification model.</li>
  <li>Open the configuration file for your client application (<em>appsettings.json</em> for C# or <em>.env</em> for Python) and update the configuration values it contains to reflect the endpoint and key for your Custom Vision <em>prediction</em> resource, the project ID for the classification project, and the name of your published model (which should be <em>fruit-classifier</em>). Save your changes.</li>
  <li>Open the code file for your client application (<em>Program.cs</em> for C#, <em>test-classification.py</em> for Python) and review the code it contains, noting the following details:
    <ul>
      <li>Namespaces from the package you installed are imported</li>
      <li>The <strong>Main</strong> function retrieves the configuration settings, and uses the key and endpoint to create an authenticated <strong>CustomVisionPredictionClient</strong>.</li>
      <li>The prediction client object is used to predict a class for each image in the <strong>test-images</strong> folder, specifying the project ID and model name for each request. Each prediction includes a probability for each possible class, and only predicted tags with a probability greater than 50% are displayed.</li>
    </ul>
  </li>
  <li>Return the integrated terminal for the <strong>test-classifier</strong> folder, and enter the following SDK-specific command to run the program:</li>
</ol>

<p><strong>C#</strong></p>

<div class="code-header mt-3 mb-0 bg-light d-flex justify-content-between border"><span class="mx-2 text-muted text-capitalize font-weight-light">code</span><button class="m-0 btn btn-code btn-sm btn-light codeBtn rounded-0 border-left text-muted font-weight-light" data-clipboard-target="#codeBlock6" type="button"><i class="fa fa-files-o mr-2" aria-hidden="true"></i>Copy</button></div><pre id="codeBlock6" class="mt-0"><code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">dotnet</span></span> run
</code></pre>

<p><strong>Python</strong></p>

<div class="code-header mt-3 mb-0 bg-light d-flex justify-content-between border"><span class="mx-2 text-muted text-capitalize font-weight-light">code</span><button class="m-0 btn btn-code btn-sm btn-light codeBtn rounded-0 border-left text-muted font-weight-light" data-clipboard-target="#codeBlock7" type="button"><i class="fa fa-files-o mr-2" aria-hidden="true"></i>Copy</button></div><pre id="codeBlock7" class="mt-0"><code class="hljs bash">python <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-classifier.py
</code></pre>

<ol>
  <li>View the label (tag) and probability scores for each prediction. You can view the images in the <strong>test-images</strong> folder to verify that the model has classified them correctly.</li>
</ol>

<h2 id="more-information">More information</h2>

<p>For more information about image classification with the Custom Vision service, see the <a href="https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/">Custom Vision documentation</a>.</p>

            </article>
        </main>
    </div>
    <footer class="fixed-bottom d-print-none">
        <nav class="navbar navbar-light bg-light d-flex justify-content-around">
            <span class="navbar-text">
                <i class="fa fa-github" aria-hidden="true"></i>
                <a href="https://github.com/MicrosoftLearning/AI-102-AIEngineer" target="_blank" class="ml-2">
                    MicrosoftLearning/AI-102-AIEngineer
                </a>
            </span>
        </nav>
    </footer>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" crossorigin="anonymous"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script src="../assets/js/script_v%3D.js"></script>



</body></html>