<!DOCTYPE html><html lang="en"><head>
        <title>
            AI-102-AIEngineer
        </title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" crossorigin="anonymous">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" crossorigin="anonymous">
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/vs.min.css">
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <link rel="stylesheet" href="../assets/css/style_v%3D.css">
    </head>
    <body data-spy="scroll" data-target="#linksMenu">
    <nav class="navbar navbar-expand-lg navbar-dark bg-black">
        <div class="container d-flex justify-content-between">
            <a class="my-1 title text-azure text-uppercase" href="../">
                AI-102-AIEngineer
            </a>
            <a href="https://github.com/MicrosoftLearning/AI-102-AIEngineer" target="_blank" class="btn btn-sm btn-outline-secondary text-light">
                <i class="fa fa-github" aria-hidden="true"></i>
                <span class="ml-2">GitHub</span>
            </a>
        </div>
    </nav>
    <div class="container">
        <main class="row extra-padding">
            <aside class="col-sm-2">       
                <nav id="linksMenu" class="toc sticky-top">
                    <ul class="nav navbar-nav flex-column">
                    <li class="nav-item"><a class="nav-link" href="#get-your-api-details">Get your API details</a></li><li class="nav-item"><a class="nav-link" href="#use-the-rest-api">Use the REST API</a></li></ul>
                </nav>         
            </aside>
            <hr class>
            <article class="col-sm-10 mb-5">
                <h1 id="analyze-video-with-video-analyzer">Analyze Video with Video Analyzer</h1>

<p>A large proportion of the data created and consumed today is in the format of video. <strong>Video Analyzer for Media</strong> is an AI-powered service that you can use to index videos and extract insights from them.</p>

<h2 id="clone-the-repository-for-this-course">Clone the repository for this course</h2>

<p>If you have already cloned <strong>AI-102-AIEngineer</strong> code repository to the environment where you‚Äôre working on this lab, open it in Visual Studio Code; otherwise, follow these steps to clone it now.</p>

<ol>
  <li>Start Visual Studio Code.</li>
  <li>Open the palette (SHIFT+CTRL+P) and run a <strong>Git: Clone</strong> command to clone the <code>https://github.com/MicrosoftLearning/AI-102-AIEngineer</code> repository to a local folder (it doesn‚Äôt matter which folder).</li>
  <li>When the repository has been cloned, open the folder in Visual Studio Code.</li>
  <li>
    <p>Wait while additional files are installed to support the C# code projects in the repo.</p>

    <blockquote>
      <p><strong>Note</strong>: If you are prompted to add required assets to build and debug, select <strong>Not Now</strong>.</p>
    </blockquote>
  </li>
</ol>

<h2 id="upload-a-video-to-video-analyzer">Upload a video to Video Analyzer</h2>

<p>First, you‚Äôll need to sign into the Video Analyzer portal and upload a video.</p>

<blockquote>
  <p><strong>Tip</strong>: If the Video Analyzer page is slow to load in the hosted lab environment, use your locally installed browser. You can switch back to the hosted VM for the later tasks.</p>
</blockquote>

<ol>
  <li>In your browser, open the Video Analyzer portal at <code>https://www.videoindexer.ai</code>.</li>
  <li>If you have an existing Video Analyzer account, sign in. Otherwise, sign up for a free account and sign in using your Microsoft account (or any other valid account type). If you have difficulty signing in, try opening a private browser session.</li>
  <li>In Video Analyzer, select the <strong>Upload</strong> option. Then select the option to <strong>enter a file URL</strong> and enter <code>https://aka.ms/responsible-ai-video</code>. Change the default name to <strong>Responsible AI</strong>, review the default settings, select the checkbox to verify compliance with Microsoft‚Äôs policies for facial recognition, and upload the file.</li>
  <li>After the file has uploaded, wait a few minutes while Video Analyzer automatically indexes it.</li>
</ol>

<blockquote>
  <p><strong>Note</strong>: In this exercise, we‚Äôre using this video to explore Video Analyzer functionality; but you should take the time to watch it in full when you‚Äôve finished the exercise as it contains useful information and guidance for developing AI-enabled applications responsibly!</p>
</blockquote>

<h2 id="review-video-insights">Review video insights</h2>

<p>The indexing process extracts insights from the video, which you can view in the portal.</p>

<ol>
  <li>In the Video Analyzer portal, when the video is indexed, select it to view it. You‚Äôll see the video player alongside a pane that shows insights extracted from the video.</li>
</ol>

<p><a href="images/video-indexer-insights.png" target="_blank"><img src="images/video-indexer-insights.png" alt="Video Analyzer with a video player and Insights pane"></a></p>

<ol>
  <li>As the video plays, select the <strong>Timeline</strong> tab to view a transcript of the video audio.</li>
</ol>

<p><a href="images/video-indexer-transcript.png" target="_blank"><img src="images/video-indexer-transcript.png" alt="Video Analyzer with a video player and Timeline pane showing the video transcript."></a></p>

<ol>
  <li>At the top right of the portal, select the <strong>View</strong> symbol (which looks similar to üóá), and in the list of insights, in addition to <strong>Transcript</strong>, select <strong>OCR</strong> and <strong>Speakers</strong>.</li>
</ol>

<p><a href="images/video-indexer-view-menu.png" target="_blank"><img src="images/video-indexer-view-menu.png" alt="Video Analyzer view menu with Transcript, OCR, and Speakers selected"></a></p>

<ol>
  <li>Observe that the <strong>Timeline</strong> pane now includes:
    <ul>
      <li>Transcript of audio narration.</li>
      <li>Text visible in the video.</li>
      <li>Indications of speakers who appear in the video. Some well-known people are  automatically recognized by name, others are indicated by number (for example <em>Speaker #1</em>).</li>
    </ul>
  </li>
  <li>Switch back to the <strong>Insights</strong> pane and view the insights show there. They include:
    <ul>
      <li>Individual people who appear in the video.</li>
      <li>Topics discussed in the video.</li>
      <li>Labels for objects that appear in the video.</li>
      <li>Named entities, such as people and brands that appear in the video.</li>
      <li>Key scenes.</li>
    </ul>
  </li>
  <li>
    <p>With the <strong>Insights</strong> pane visible, select the <strong>View</strong> symbol again, and in the list of insights, add <strong>Keywords</strong> and <strong>Sentiments</strong> to the pane.</p>

    <p>The insights found can help you determine the main themes in the video. For example, the <strong>topics</strong> for this video show that it is clearly about technology, social responsibility, and ethics.</p>
  </li>
</ol>

<h2 id="search-for-insights">Search for insights</h2>

<p>You can use Video Analyzer to search the video for insights.</p>

<ol>
  <li>In the <strong>Insights</strong> pane, in the <strong>Search</strong> box, enter <em>Bee</em>. You may need to scroll down in the Insights pane to see results for all types of insight.</li>
  <li>Observe that one matching <em>label</em> is found, with its location in the video indicated beneath.</li>
  <li>Select the beginning of the section where the presence of a bee is indicated, and view the video at that point (you may need to pause the video and select carefully - the bee only appears briefly!)</li>
  <li>Clear the <strong>Search</strong> box to show all insights for the video.</li>
</ol>

<p><a href="images/video-indexer-search.png" target="_blank"><img src="images/video-indexer-search.png" alt="Video Analyzer search results for Bee"></a></p>

<h2 id="edit-insights">Edit insights</h2>

<p>You can use Video Analyzer to edit the insights that have been found, adding custom information to make even more sense of the video.</p>

<ol>
  <li>Rewind the video to the start and view the <strong>people</strong> listed at the top of the <strong>Insights</strong> pane. Observe that some people have been recognized, including <strong>Eric Horwitz</strong>, a computer scientist and Technical Fellow at Microsoft.</li>
</ol>

<p><a href="images/video-indexer-known-person.png" target="_blank"><img src="images/video-indexer-known-person.png" alt="Video Analyzer insights for a known person"></a></p>

<ol>
  <li>Select the photo of Eric Horwitz, and view the information underneath - expanding the <strong>Show biography</strong> section to see information about this person.</li>
  <li>Observe that the locations in the video where this person appears are indicated. You can use these to view those sections of the video.</li>
  <li>In the video player, find the person speaking at approximately 0:34:</li>
</ol>

<p><a href="images/video-indexer-unknown-person.png" target="_blank"><img src="images/video-indexer-unknown-person.png" alt="Video Analyzer insights for an unknown person"></a></p>

<ol>
  <li>Observe that this person is not recognized, and has been assigned a generic name such as <strong>Unknown #1</strong>. However, the video does include a caption with this person‚Äôs name, so we can enrich the insights by editing the details for this person.</li>
  <li>At the top right of the portal, select the <strong>Edit</strong> icon (üñâ). Then change the name of the unknown person to <strong>Natasha Crampton</strong>.</li>
</ol>

<p><a href="images/video-indexer-edit-name.png" target="_blank"><img src="images/video-indexer-edit-name.png" alt="Editing a person in Video Analyzer"></a></p>

<ol>
  <li>After you have made the name change, search the <strong>Insights</strong> pane for <em>Natasha</em>. The results should include one person, and indicate the sections of the video in which they appear.</li>
  <li>At the top left of the portal, expand the menu (‚â°) and select the <strong>Model customizations</strong> page. Then on the <strong>People</strong> tab, observe that the <strong>Default</strong> people model has one person in it. Video Analyzer has added the person you named to a people model, so that they will be recognized in any future videos you index in your account.</li>
</ol>

<p><a href="images/video-indexer-custom-model.png" target="_blank"><img src="images/video-indexer-custom-model.png" alt="The default people model in Video Analyzer"></a></p>

<p>You can add images of people to the default people model, or add new models of your own. This enables you to define collections of people with images of their face so that Video Analyzer can recognize them in your videos.</p>

<p>Observe also that you can also create custom models for language (for example to specify industry-specific terminology you want Video Analyzer to recognize) and brands (for example, company or product names).</p>

<h2 id="use-video-analyzer-widgets">Use Video Analyzer widgets</h2>

<p>The Video Analyzer portal is a useful interface to manage video indexing projects. However, there may be occasions when you want to make the video and its insights available to people who don‚Äôt have access to your Video Analyzer account. Video Analyzer provides widgets that you can embed in a web page for this purpose.</p>

<ol>
  <li>In Visual Studio Code, in the <strong>16-video-indexer</strong> folder, open <strong>analyze-video.html</strong>. This is a basic HTML page to which you will add the Video Analyzer <strong>Player</strong> and <strong>Insights</strong> widgets. Note the reference to the <strong>vb.widgets.mediator.js</strong> script in the header - this script enables multiple Video Analyzer widgets on the page to interact with one another.</li>
  <li>In the Video Analyzer portal, return to the <strong>Media files</strong> page and open your <strong>Responsible AI</strong> video.</li>
  <li>Under the video player, select <strong>&lt;/&gt; Embed</strong> to view the HTML iframe code to embed the widgets.</li>
  <li>In the <strong>Share and Embed</strong> dialog box, select the <strong>Player</strong> widget, set the video size to 560 x 315,  and then copy the embed code to the clipboard.</li>
  <li>In Visual Studio Code, in the <strong>analyze-video.html</strong> file, paste the copied code under the comment <strong>&lt;‚Äì Player widget goes here ‚Äì &gt;</strong>.</li>
  <li>Back in the <strong>Share and Embed</strong> dialog box, select the <strong>Insights</strong> widget and then copy the embed code to the clipboard. Then close the <strong>Share and Embed</strong> dialog box, switch back to Visual Studio Code, and paste the copied code under the comment <strong>&lt;‚Äì Insights widget goes here ‚Äì &gt;</strong>.</li>
  <li>Save the file. Then in the <strong>Explorer</strong> pane, right-click <strong>analyze-video.html</strong> and select <strong>Reveal in File Explorer</strong>.</li>
  <li>In File Explorer, open <strong>analyze-video.html</strong> in your browser to see the web page.</li>
  <li>Experiment with the widgets, using the <strong>Insights</strong> widget to search for insights and jump to them in the video.</li>
</ol>

<p><a href="images/video-indexer-widgets.png" target="_blank"><img src="images/video-indexer-widgets.png" alt="Video Analyzer widgets in a web page"></a></p>

<h2 id="use-the-video-analyzer-rest-api">Use the Video Analyzer REST API</h2>

<p>Video Analyzer provides a REST API that you can use to upload and manage videos in your account.</p>

<h3 id="get-your-api-details">Get your API details</h3>

<p>To use the Video Analyzer API, you need some information to authenticate requests:</p>

<ol>
  <li>In the Video Analyzer portal, expand the menu (‚â°) and select the <strong>Account settings</strong> page.</li>
  <li>Note the <strong>Account ID</strong> on this page - you will need it later.</li>
  <li>Open a new browser tab and go to the Video Analyzer developer portal at <code>https://api-portal.videoindexer.ai</code>, signing in using the credentials for your Video Analyzer account.</li>
  <li>On the <strong>Profile</strong> page, view the <strong>Subscriptions</strong> associated with your profile.</li>
  <li>On the page with your subscription(s), observe that you have been assigned two keys (primary and secondary) for each subscription. Then select <strong>Show</strong> for any of the keys to see it. You will need this key shortly.</li>
</ol>

<h3 id="use-the-rest-api">Use the REST API</h3>

<p>Now that you have the account ID and an API key, you can use the REST API to work with videos in your account. In this procedure, you‚Äôll use a PowerShell script to make REST calls; but the same principles apply with HTTP utilities such as cURL or Postman, or any programming language capable of sending and receiving JSON over HTTP.</p>

<p>All interactions with the Video Analyzer REST API follow the same pattern:</p>

<ul>
  <li>An initial request to the <strong>AccessToken</strong> method with the API key in the header is used to obtain an access token.</li>
  <li>Subsequent requests use the access token to authenticate when calling REST methods to work with videos.</li>
</ul>

<ol>
  <li>In Visual Studio Code, in the <strong>16-video-indexer</strong> folder, open <strong>get-videos.ps1</strong>.</li>
  <li>In the PowerShell script, replace the <strong>YOUR_ACCOUNT_ID</strong> and <strong>YOUR_API_KEY</strong> placeholders with the account ID and API key values you identified previously.</li>
  <li>Observe that the <em>location</em> for a free account is ‚Äútrial‚Äù. If you have created an unrestricted Video Analyzer account (with an associated Azure resource), you can change this to the location where your Azure resource is provisioned (for example ‚Äúeastus‚Äù).</li>
  <li>Review the code in the script, noting that invokes two REST methods: one to get an access token, and another to list the videos in your account.</li>
  <li>Save your changes, and then at the top-right of the script pane, use the <strong>‚ñ∑</strong> button to run the script.</li>
  <li>View the JSON response from the REST service, which should contain details of the <strong>Responsible AI</strong> video you indexed previously.</li>
</ol>

<h2 id="more-information">More information</h2>

<p>For more information about <strong>Video Analyzer</strong>, see the <a href="https://docs.microsoft.com/azure/azure-video-analyzer/video-analyzer-for-media-docs/">Video Analyzer documentation</a>.</p>

            </article>
        </main>
    </div>
    <footer class="fixed-bottom d-print-none">
        <nav class="navbar navbar-light bg-light d-flex justify-content-around">
            <span class="navbar-text">
                <i class="fa fa-github" aria-hidden="true"></i>
                <a href="https://github.com/MicrosoftLearning/AI-102-AIEngineer" target="_blank" class="ml-2">
                    MicrosoftLearning/AI-102-AIEngineer
                </a>
            </span>
        </nav>
    </footer>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" crossorigin="anonymous"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script src="../assets/js/script_v%3D.js"></script>



</body></html>